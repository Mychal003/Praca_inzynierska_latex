\chapter{Wprowadzenie}\label{chapter:introduction}

Szybki postęp w dziedzinie sztucznej inteligencji, a w szczególności w tworzeniu dużych modeli językowych (LLM -- Large Language Models), otworzył nowe możliwości w zakresie przetwarzania i analizy tekstu. Współczesne modele -- np. GPT-4 -- potrafią generować odpowiedzi na pytania użytkowników w sposób przypominający konwersację z drugim człowiekiem. Jednakże same modele językowe mają istotne ograniczenie -- ich wiedza pochodzi wyłącznie z danych treningowych. Oznacza to, że nie mają one dostępu do wewnętrznych dokumentów firmowych czy szczegółowej dokumentacji technicznej.

Pomimo, że teoretycznie istnieje możliwość dostosowania modelu do konkretnej dziedziny poprzez proces finetuningu, w praktyce jest to często mało opłacalne. Takie rozwiązanie jest bowiem obarczone wieloma wadami: jest kosztowne, czasochłonne oraz wymaga przygotowania dużych zestawów wysokiej jakości danych. Przy tym nie bez znaczenia jest fakt, że nawet niewielkie błędy w gromadzonych danych mogą zaburzyć działanie modelu. Ponadto, po zakończeniu finetuningu model staje się „zamknięty” na bieżące aktualizacje -- aby wprowadzić nowe informacje, konieczne jest ponowne przeprowadzenie procesu trenowania. Rodzi to pytanie o sens stosowania tego podejścia w środowiskach, w których dokumentacja ulega regularnym zmianom.

To istotne ograniczenie można wyeliminować wykorzystując architekturę RAG (Retrieval-Augmented Generation), w której proces generowania odpowiedzi jest wspierany mechanizmem wyszukiwania informacji. System odnajduje informacje powiązane z pytaniem użytkownika, \\a następnie przekazuje je modelowi językowemu jako kontekst. W konsekwencji model może udzielać precyzyjnych odpowiedzi dotyczących dowolnych materiałów źródłowych -- bez potrzeby trenowania czy modyfikowania samego modelu.

Niniejsza praca przedstawia projekt, implementację oraz ewaluację systemu RAG przeznaczonego do obsługi dokumentacji technicznej. System został przetestowany na instrukcji obsługi routera TP-Link Archer D7, jednakże jego architektura pozwala na zastosowanie \\z dowolnymi dokumentami PDF.

Głównym wkładem pracy jest implementacja kompletnego rozwiązania oraz weryfikacja jego skuteczności przy użyciu zestawu metryk oceniających zarówno jakość wyszukiwania, \\jak i generowania odpowiedzi. Analiza uzyskanych wyników sugeruje również, że odpowiednie projektowanie promptów (prompt engineering) ma kluczowe znaczenie dla poprawności merytorycznej systemu i eliminacji halucynacji.

\newpage
\section{Sformułowanie problemu}

Dokumentacja nowoczesnych, zaawansowanych produktów często liczy dziesiątki \\lub setki stron. Użytkownicy szukający konkretnej informacji muszą przeszukiwać dokumenty ręcznie, co jest czasochłonne. Tradycyjne wyszukiwanie tekstowe (Ctrl+F) wymaga znajomości dokładnych słów kluczowych i nie radzi sobie z pytaniami zadawanymi w języku naturalnym.

\textbf{Problem badawczy:} Jak zbudować system, który automatycznie odpowiada na pytania użytkowników na podstawie dokumentacji technicznej, zachowując wysoką dokładność i nie generując przy tym nieprawdziwych informacji (halucynacji)?

\textbf{Pytania badawcze:}
\begin{enumerate}
    \item Jaka jest skuteczność zaimplementowanego systemu RAG w obsłudze zapytań technicznych (faktograficznych, proceduralnych i diagnostycznych)?
    \item W jakim stopniu inżynieria promptów (prompt engineering) wpływa na jakość i poprawność generowanych odpowiedzi?
    \item Czy ocena dokonana przez model językowy (LLM Judge) jest spójna z wynikami metryk automatycznych (ROUGE, Semantic Similarity)?
\end{enumerate}

\textbf{Znaczenie badania:} Systemy RAG znajdują coraz szersze zastosowanie w obsłudze klienta, wewnętrznych systemach firmowych i asystentach AI. Analiza czynników wpływających na ich jakość pozwala budować lepsze rozwiązania i unikać typowych błędów projektowych.

\textbf{Ograniczenia badań:}
\begin{itemize}
    \item Ewaluacja przeprowadzona na jednym dokumencie (instrukcja routera, 119 stron).
    \item Dataset ewaluacyjny zawiera 25 pytań z trzech kategorii.
    \item System obsługuje dokumenty w formacie PDF.
\end{itemize}

\section{Cele pracy}

Głównym celem pracy jest zaprojektowanie i zaimplementowanie systemu RAG wraz z jego kompleksową ewaluacją, służącego do automatycznego odpowiadania na pytania użytkownika na podstawie dostarczonej dokumentacji technicznej.

\textbf{Cele szczegółowe:}
\begin{enumerate}
    \item \textbf{Implementacja systemu RAG} -- stworzenie działającego systemu obejmującego przetwarzanie PDF, tworzenie embeddingów, bazę wektorową FAISS oraz generowanie odpowiedzi z użyciem modelu GPT-4o.
    
    \item \textbf{Opracowanie metodologii ewaluacji} -- stworzenie zestawu narzędzi do oceny jakości systemu obejmującego:
    \begin{itemize}
        \item metryki wyszukiwania (Precision, Recall, MRR, NDCG),
        \item metryki generacji (ROUGE, Semantic Similarity),
        \item ocenę przez model językowy (LLM Judge).
    \end{itemize}
    
    \item \textbf{Przeprowadzenie ewaluacji} -- weryfikacja poprawności działania systemu dla przyjętej konfiguracji parametrów na przygotowanym zbiorze danych testowych.
    
    \item \textbf{Optymalizacja promptów} -- zaprojektowanie i przetestowanie instrukcji systemowych (promptów) w celu maksymalizacji jakości odpowiedzi.
    
    \item \textbf{Analiza wyników} -- ocena skuteczności systemu z udziałem przyjętych metryk oraz sformułowanie wniosków dotyczących jego wydajności.
\end{enumerate}

\section{Struktura pracy}
Praca została podzielona na sześć rozdziałów. 
Rozdział \ref{chapter:introduction} stanowi wprowadzenie do tematyki i definiuje cel pracy. 
Rozdział \ref{chapter:related} zawiera przegląd literatury dotyczącej modeli językowych i architektury RAG. 
Rozdział \ref{chapter:methodology} przedstawia metodologię badawczą oraz szczegółowe wyniki ewaluacji systemu. Rozdział \ref{chapter:implementation} opisuje szczegóły techniczne implementacji systemu.
Całość podsumowuje rozdział \ref{chapter:conclusions}, zawierający wnioski końcowe oraz kierunki dalszego rozwoju.